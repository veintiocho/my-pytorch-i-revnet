# logger options
exp_name: 'exp_shuffle'
#description:
#   1. with two layer content loss
#   2. normalized content loss
#   3. update encoder lightly
#   4. modify the coeffcient of losses
#   5. with cycle_recon
#
#
# load options
is_resume: False
pretrained_ckpt: 'models/EXP1_5_1_140000.pth.tar'

classCount: 10
guide_net: 'vgg'
# optimization options
max_epoch: 200              # maximum number of training iterations
batch_size: 128                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.1                    # initial learning rate
lr_decay: 0.00009             # learning rate scheduler
step_size: 10000              # how often to decay learning rate100000
gamma: 0.5                    # how much to decay learning rate
gan_w: 5                      # weight of adversarial loss
dis_w: 1
gen_style_w: 20               # weight of image reconstruction loss
gen_content_w: 2              # weight of style reconstruction loss
recon_content_w: 0.001        # weight of content reconstruction loss
recon_style_w: 0.0002
g_recon_content_w: 0.001

# data options
input_dim_c: 3                              # number of image channels [1/3]
n_threads: 8                                # number of data loading threads
new_size: 256                               # first resize the shortest image side to this size
crop_image_height: 256                      # random crop image of this height
crop_image_width: 256                       # random crop image of this width
content_dir: '../Datasets/ContentImages/'
style_dir: '../Datasets/MangaImages/'
